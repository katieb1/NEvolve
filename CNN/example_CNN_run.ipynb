{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[1,     5] loss: 247.530\n",
      "[2,     5] loss: 44.169\n",
      "[3,     5] loss: 251.536\n",
      "[4,     5] loss: 233.053\n",
      "[5,     5] loss: 246.758\n",
      "[6,     5] loss: 233.274\n",
      "[7,     5] loss: 239.516\n",
      "[8,     5] loss: 236.109\n",
      "[9,     5] loss: 236.623\n",
      "[10,     5] loss: 217.729\n",
      "[11,     5] loss: 231.625\n",
      "[12,     5] loss: 234.586\n",
      "[13,     5] loss: 211.129\n",
      "[14,     5] loss: 229.567\n",
      "[15,     5] loss: 202.959\n",
      "[16,     5] loss: 37.651\n",
      "[17,     5] loss: 36.601\n",
      "[18,     5] loss: 249.259\n",
      "[19,     5] loss: 243.550\n",
      "[20,     5] loss: 241.254\n",
      "Finished Training\n",
      "Total time run: 0.5394 minutes\n"
     ]
    }
   ],
   "source": [
    "import CNN_draft1\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'CNN_draft1' from '/Users/katie/queens_bio/NE_project/NEvolve/CNN/CNN_draft1.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_draft1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[1,     5] loss: 230.235\n",
      "[2,     5] loss: 254.011\n",
      "[3,     5] loss: 10.818\n",
      "[4,     5] loss: 38.728\n",
      "[5,     5] loss: 211.808\n",
      "[6,     5] loss: 231.649\n",
      "[7,     5] loss: 251.610\n",
      "[8,     5] loss: 64.385\n",
      "[9,     5] loss: 212.570\n",
      "[10,     5] loss: 256.505\n",
      "[11,     5] loss: 212.618\n",
      "[12,     5] loss: 256.107\n",
      "[13,     5] loss: 238.783\n",
      "[14,     5] loss: 236.976\n",
      "[15,     5] loss: 63.855\n",
      "[16,     5] loss: 255.372\n",
      "[17,     5] loss: 254.802\n",
      "[18,     5] loss: 237.852\n",
      "[19,     5] loss: 230.351\n",
      "[20,     5] loss: 52.337\n",
      "Finished Training\n",
      "Total time run: 0.5378 minutes\n"
     ]
    }
   ],
   "source": [
    "%run 'CNN_draft1.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('./test.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('./toy_dat/sliced_data.npz') as data:\n",
    "    param = data['param']\n",
    "    raw_sim = data['sim']\n",
    "    pos = data['pos']\n",
    "\t\n",
    "# Normalize to mean of 0, sd of 1\n",
    "\n",
    "sim = (raw_sim - 0.5) / 0.5 # May need something more efficient for the full set?\n",
    "# print(raw_sim[0,1])\n",
    "# print(sim[0,1])\n",
    "\n",
    "tensor = torch.from_numpy(sim)\n",
    "tensor = tensor.double()\n",
    "tensor = tensor.unsqueeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ...,  True, False, False],\n",
       "       [False,  True, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ...,  True, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [ True, False,  True, ..., False, False, False]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sim[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 72, 1263])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape # same as snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_p = np.array([list(item) for item in param])\n",
    "new_p = new_p[:, 2:7]\n",
    "new_p = torch.from_numpy(np.array(new_p))\n",
    "# print(new_p.shape)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(tensor, new_p)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size = 20,\n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [20, 6, 68, 1259]             156\n",
      "         MaxPool2d-2           [20, 6, 17, 314]               0\n",
      "            Conv2d-3          [20, 16, 13, 310]           2,416\n",
      "         MaxPool2d-4            [20, 16, 3, 77]               0\n",
      "            Linear-5                  [20, 120]         443,640\n",
      "            Linear-6                   [20, 84]          10,164\n",
      "            Linear-7                    [20, 5]             425\n",
      "================================================================\n",
      "Total params: 456,801\n",
      "Trainable params: 456,801\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 6.94\n",
      "Forward/backward pass size (MB): 93.70\n",
      "Params size (MB): 1.74\n",
      "Estimated Total Size (MB): 102.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1, 72, 1263), batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=3696, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[1,     5] loss: 56.977\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[2,     5] loss: 18.966\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[3,     5] loss: 252.761\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[4,     5] loss: 225.861\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[5,     5] loss: 235.039\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[6,     5] loss: 227.726\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[7,     5] loss: 244.501\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[8,     5] loss: 218.163\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[9,     5] loss: 230.130\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[10,     5] loss: 235.735\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[11,     5] loss: 232.379\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[12,     5] loss: 216.666\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[13,     5] loss: 215.610\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[14,     5] loss: 218.601\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[15,     5] loss: 210.855\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[16,     5] loss: 52.860\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[17,     5] loss: 232.590\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[18,     5] loss: 231.666\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[19,     5] loss: 241.032\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "[20,     5] loss: 203.802\n",
      "torch.Size([20, 1, 72, 1263])\n",
      "Finished Training\n",
      "Total time run: 0.5500 minutes\n"
     ]
    }
   ],
   "source": [
    "# Main imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# PyTorch shorthands\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "### data loader will need to be modified!! ###\n",
    "# Currently using toy data set\n",
    "with np.load('./toy_dat/sliced_data.npz') as data:\n",
    "    param = data['param']\n",
    "    raw_sim = data['sim']\n",
    "    pos = data['pos']\n",
    "\t\n",
    "# Normalize to mean of 0, sd of 1\n",
    "\n",
    "sim = (raw_sim - 0.5) / 0.5 # May need something more efficient for the full set?\n",
    "# print(raw_sim[0,1])\n",
    "# print(sim[0,1])\n",
    "\n",
    "tensor = torch.from_numpy(sim)\n",
    "tensor = tensor.double()\n",
    "tensor = tensor.unsqueeze(dim = 1)\n",
    "\n",
    "new_p = np.array([list(item) for item in param])\n",
    "new_p = new_p[:, 2:7]\n",
    "new_p = torch.from_numpy(np.array(new_p))\n",
    "# print(new_p.shape)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(tensor, new_p)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size = 20,\n",
    "                                          shuffle = True)\n",
    "# print(trainloader)\n",
    "# tensor = tensor.unsqueeze(dim = 1)\n",
    "# print(tensor.shape)\n",
    "# print(tensor.shape)\n",
    "#t1 = tensor[1,1]\n",
    "\n",
    "# Build the net\n",
    "\n",
    "class Net(nn.Module):\n",
    "    # Define all the transformations we want here\n",
    "    def __init__(self):\n",
    "        # Inherit behaviour from PyTorch class\n",
    "        super(Net, self).__init__()\n",
    "        # Convolutional transforms\n",
    "        # input to Conv2d should be a 4D tensor [batch_size, channel, l, w]\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Regular neural net transforms after unwrap\n",
    "        self.fc1 = nn.Linear(16 * 3 * 77, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 5)\n",
    "\n",
    "    # Define all the steps for one full forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 16 * 3 * 77)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# Loss and optimizer functions\n",
    "\n",
    "criterion = F.mse_loss\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum = 0.7)\n",
    "\n",
    "n_epoch = 20\n",
    "\n",
    "net = net.double()\n",
    "\n",
    "# Load CUDA if present\n",
    "# to load CUDA in colab, go to runtime->change runtime type and select gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: %s\" % device)\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "for epoch in range(n_epoch): # loope over dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    count_b = 0\n",
    "    for inputs, labels in trainloader:\n",
    "        count_b += 1\n",
    "        # data is a list of [inputs, labels]\n",
    "        #inputs, labels = data[0], data[1] # note that moving tensors to the device is done _out of place_\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        print(inputs.shape)\n",
    "        # print(f\"labels as long: {labels.long()}\")\n",
    "        # print(inputs)\n",
    "        #inputs = tensor[i,:]\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward -> backward -> optimize\n",
    "        outputs = net(inputs)\n",
    "        # print(f\"output shape: {outputs.shape}\" )\n",
    "        # print(f\"label shape: {labels.shape}\" )\n",
    "        # outputs = outputs.unsqueeze(dim=0)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if count_b % 5 == 4: # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, count_b + 1, running_loss / 5))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Total time run: {(toc-tic)/60:0.4f} minutes\")\n",
    "\n",
    "### Where we save to needs to be modified!! ###\n",
    "torch.save(net.state_dict(), \"./test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
